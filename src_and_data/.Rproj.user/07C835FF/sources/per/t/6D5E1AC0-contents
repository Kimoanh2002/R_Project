---
title: "model"
output: html_document
date: "2025-05-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Import các thư viện cần thiết**
```{r}
# Danh sách các gói
required_packages <- c("tidyverse", "smotefamily", "rpart", "randomForest", "pROC", "caret", "reshape2")

# Kiểm tra 
install_if_missing <- function(packages) {
  for (pkg in packages) {
    if (!requireNamespace(pkg, quietly = TRUE)) {
      install.packages(pkg, dependencies = TRUE)
    }
    library(pkg, character.only = TRUE)
  }
}
install_if_missing(required_packages)
```

**Lẫy dữ liệu khi đã được tiền xử lý**
```{r}
data <- read.csv("data_processed.csv", sep = ',')
print(data)
```
- Thuộc tính cần dự đoán là Exited (Churn khách hàng) có hai lớp là 0 (không quay lại) hoặc 1 (có quay lại). Do đó, ta có thể xác định được rằng đây là một bài toán phân loại (classification). Ở quá trình khai phá dữ liệu ta đã nắm bắt được dữ liệu và có thể đây là một bài toán phi tuyến tính. Vì vậy, có thể phân tích kỹ hơn để xác định thực chất có phải là bài toán tuyến tính hay phi tuyến tính cho dự đoán khách hàng ngân hàng hay không. 

**Kiểm tra tỷ lệ Balance = 0**
```{r}
balance_0 <- data %>%
  filter(Balance==0) %>%
  count(Balance)
```

```{r}
print(3478 / 9626)
```
- Kiểm tra tương tác của một vài biến như Balance đối với Exited để xem loại tuyến tính nào. Đối với Balance (Số dư trong tài khoản), thông thường với những tài khoản có số dư bằng 0 họ thường có xu hướng ít không sử dụng hoặc đã rời bỏ ngân hàng, trong dữ liệu kiểm tra thấy với Balance = 0 chiếm 36,1% tổng số người dùng, tuy nhiên tỉ lệ rời bỏ (Exited = 0) chỉ chiếm khoảng 20%. Do đó có thể được ngay không phải tất cả khách hàng có số dư bằng 0 đều rời bỏ, có thể phụ thuộc vào những yếu tố khác như Age, Comlain,... 
--> Kết luận được rằng đây là một bài toán phi tuyến tính, kẻ ranh giới quyết định giữa hai lớp (Exited = 0 và 1) không thể được biểu diễn bằng một đường thẳng/đường phẳng trong không gian đặc trưng. Vì là bài toán phân loại và phi tuyến tính, có những mô hình khả thi như Decision Tree, Random Forest, XGBoost hay SVM.


# 2. Xử lý dữ liệu cho mô hình
**Dữ liệu đã được tiền xử lý để sử dung chung, do đó cần phải xử lý tiếp theo để phù hợp cho quá trình modeling dữ liệu**

**Loại bỏ các biến không được sử dụng**
- Loại bỏ các biến không được sử dụng trong mô hình: RowNumber, CustomerID và Surname. Do các biến này là biến định danh và có số lượng mẫu rất lớn, ngoài ra các biến này cũng không ảnh hưởng đến tỷ lệ rời đi của khách hàng. Ngoài ra như đã phân tích trước đó, biến Complain có độ tương quan lên đến 100% với biến mục tiêu Excited, biến này này là một biến leakage, nên cần loại bỏ để tránh overfiting cho mô hình và làm cho bài toán thực tế hơn

```{r}
data_model <- subset(data, select = -c(RowNumber, CustomerId, Surname, Complain))
```

```{r}
print(data_model)
```
**Mã hoá các biến phân loại**
- Mã hoá các biến phân loại thành dạng các cột nhị phân 0 hoặc 1, tránh giả định thứ tự, phù hợp với hầu hết mô hình học máy, thích hợp để phân tích và lựa chọn mô hình sau này

**Chuyển các biến phân loại thành kiểu dữ liệu factor**
```{r}
data_model$Geography <- as.factor(data_model$Geography)
data_model$Gender <- as.factor(data_model$Gender)
data_model$Card.Type <- as.factor(data_model$Card.Type)
data_model$Exited <- as.factor(data_model$Exited)
data_model$HasCrCard <- as.factor(data_model$HasCrCard)
data_model$IsActiveMember <- as.factor(data_model$IsActiveMember)
```

**One-hot encoding đối với các biến phân loại**
```{r}
dummy <- dummyVars(~ Geography + Gender + Card.Type, data = data_model)
encoded_data <- predict(dummy, newdata = data_model) %>%
  as.data.frame() %>%
  bind_cols(data_model)  # Kết hợp với dữ liệu gốc

encoded_data <- subset(encoded_data, select = -c(Geography, Gender, Card.Type))
print(encoded_data)
```

**Kiểm tra độ cân bằng của các lớp**
```{r}
exited_freq <- table(encoded_data$Exited)
cap <- c(7676,1950) 
exited <- c(0, 1)
percent <- round(cap / sum(cap) * 100, 2)
label <- paste(exited, ": ", percent, "%", sep="")
excited_layers <- pie(exited_freq, labels=label,main="Tỷ lệ Churn (Exited)")
```
- Ta thấy lớp 0 có 7676 mẫu (chiếm 79.7%) và lớp 1 chỉ có 1950 mẫu (chiếm 20.25%). Do đó lớp bị mất cân bằng, mô hình có thể học tốt lớp chiếm ưu thế nhưng bỏ qua lớp thiểu số, dẫn đến hiệu suất kém trên lớp thiểu số. Vì vậy cần phải sử dụng các kỹ thuật để cân bằng lớp.

**Cân bằng lớp bằng SMOTE**
-Để tránh overfitting của oversampling và dữ liệu đủ lớn để tạo mẫu tổng hợp, nhóm sử dụng SMOTE để thực hiện việc cân bằng lớp cho Exited.
```{r}
library(smotefamily)

# Tách biến mục tiêu và đặc trưng
X <- encoded_data[, !names(encoded_data) %in% "Exited"] 
Y <- encoded_data$Exited 

X <- as.data.frame(lapply(X, as.numeric))

# Áp dụng SMOTE
smote_result <- SMOTE(X = X, target = Y, K = 5)

# Lấy dữ liệu 
smote_data <- smote_result$data
colnames(smote_data)[ncol(smote_data)] <- "Exited" # Đặt lại tên cột mục tiêu

# Kiểm tra
table(smote_data$Exited)
prop_data <- prop.table(table(smote_data$Exited)) * 100
```

```{r}
smote_data$Exited <- as.factor(smote_data$Exited)
```

**Kiểm tra kết quả sau khi cân bằng**
```{r}
pie(prop_data, 
    labels = paste(names(prop_data), round(prop_data, 1), "%"), 
    main = "Phân phối lớp Exited sau SMOTE", 
    col = c("lightblue", "lightgreen"), 
    clockwise = TRUE)
```
- Sau cân bằng, như trên biểu đồ tròn đã hiển thị, hai lớp 0 và 1 đã có tỉ lệ khá cân bằng với 43.4% cho lớp 1 và 56.7% cho lớp 0. Cả hai lớp chỉ chênh lệch khoảng độ 13,4%, tỷ lệ này chấp nhận được, tuy nhiên khi đưa vào mô hình có thể cần tinh chỉnh các tham số nhằm trường hợp mô hình nhạy cảm với các giá trị 0 hơn.

#3. Xây dựng mô hình
- Sau khi đã xử lý dữ liệu phù hợp, nhóm lần lượt đưa vào các mô hình máy học phù hợp như Decision Tree, Random Forest  và sau đó đánh giá hiệu suất của chúng. Thực hiện chia dữ liệu với tỷ lệ 80/20, 80% để huấn luyện và 20% để kiểm tra.

**Import các thư viện cần thiết**
```{r}
library(rpart)          # Dùng cho Decision Tree
library(randomForest)   # Dùng cho Random Forest
library(pROC)           # Dùng để tính ROC-AUC
```

**Chia tệp dữ liệu để huấn luyện và kiểm tra**
```{r}
set.seed(123) 
trainIndex <- createDataPartition(smote_data$Exited, p = 0.8, list = FALSE)
train_data <- smote_data[trainIndex, ]
test_data <- smote_data[-trainIndex, ]
```

##3.1. Mô hình Decision Tree
- Nhóm thực hiện xây dựng mô hình Decision Tree đơn giản và chưa cần điều chỉnh các tham số do đã thực hiện cân bằng lớp SMOTE, chỉ sử dụng những tham số mặc định. Cài đặt mô hình như sau:

**Xây dựng mô hình Decision Tree**
```{r}
#Decision Tree
dt_model <- rpart(
  Exited ~ .,
  data = train_data,
  method = "class",
)
# Dự đoán trên tập kiểm tra
dt_pred <- predict(dt_model, test_data, type = "class")
dt_prob <- predict(dt_model, test_data, type = "prob")[, 2]  # Xác suất cho lớp 1
```

# 3.2. Mô hình Random Forest
-Xây dựng mô hình Random Forest đơn giản và có các tham số cơ bản như:
n_tree = 500 (Số lượng cây quyết định trong Random Forest): Giá trị 500 là một lựa chọn phổ biến, đủ lớn để đảm bảo độ chính xác mà không quá tốn tài nguyên.
node_size = 5 (Số lượng mẫu tối thiểu tại mỗi nút lá của một cây quyết định): Giá trị này cho phép cây sâu hơn, có thể nắm bắt được các mẫu phức tạp hơn.
Sau khi xác định được các tham số cơ bản, thực hiện cài đặt mô hình qua thư viện randomForest:

**Xây dựng mô hình Random Forest**
```{r}
#Random Forest
rf_model <- randomForest(
  Exited ~ .,
  data = train_data,
  ntree = 500,
  nodesize = 5,
  importance = TRUE
)

# Dự đoán trên tập kiểm tra
rf_pred <- predict(rf_model, test_data)
rf_prob <- predict(rf_model, test_data, type = "prob")[, 2]  # Xác suất cho lớp 1
```

```{r}
str(encoded_data)
```
#4. Đánh giá và lựa chọn mô hình dự đoán

**Sử dụng ma trận nhầm lẫn**
```{r}
#Ma trận nhầm lẫn và các chỉ số đánh giá
# Decision Tree
dt_confusion <- confusionMatrix(dt_pred, test_data$Exited, positive = "1")
print("Các chỉ số đánh giá của Decision Tree:")
print(dt_confusion)

# Random Forest
rf_confusion <- confusionMatrix(rf_pred, test_data$Exited, positive = "1")
print("Các chỉ số đánh giá của Random Forest:")
print(rf_confusion)
```
Ta cần chú ý những chỉ số sau:
Đối với Decision Tree:
  - Accuracy khoảng 0.8362, mô hình dự đoán đúng 83.62% số mẫu trong tập kiểm tra. Đây là một con số khá tốt, nhưng vì dữ liệu đã được cân bằng (bằng SMOTE), khoảng tin cậy 95% (0.8217, 0.85) cho thấy độ chính xác ổn định, Accuracy là một chỉ số đáng tin cậy để đánh giá tổng thể.
  - Kappa đo được 0.6568 mức độ đồng thuận giữa dự đoán và thực tế cho thấy mô hình có hiệu suất tốt trong việc phân loại, nhưng không quá xuất sắc.
  - Sensitivity (Recall) đo tỷ lệ các mẫu thực tế là lớp 1 (Exited = 1) được dự đoán đúng. Mô hình chỉ phát hiện được 69.2% các trường hợp khách hàng thực sự rời bỏ. Đây là một con số trung bình khá, cho thấy mô hình bỏ sót nhiều trường hợp rời bỏ (30.8% bị bỏ sót).
  - Specificity đo tỷ lệ các mẫu thực tế là lớp 0 (Exited = 0) được dự đoán đúng. Mô hình dự đoán rất tốt các trường hợp không rời bỏ, với tỷ lệ 94.53%. Điều này cho thấy mô hình có xu hướng thiên nhẹ về dự đoán lớp 0.

Đối với Random Forest:
  - Accuracy khoảng 0.8965, mô hình dự đoán đúng 89.65% số mẫu trong tập kiểm tra. Đây là một con số khá tốt, nhưng vì dữ liệu đã được cân bằng (bằng SMOTE), khoảng tin cậy 95% (0.8844, 0.9077) cho thấy độ chính xác ổn định, Accuracy là một chỉ số đáng tin cậy để đánh giá tổng thể.
  - Kappa ​​đo được 0.7857 điều này cho thấy mô hình Random Forest có khả năng dự đoán đáng tin cậy, đặc biệt trong bối cảnh tập dữ liệu hơi mất cân bằng.
  - Sensitivity (Recall) Mô hình phát hiện được 81.2% các trường hợp khách hàng thực sự rời bỏ. Đây là một con số tốt, cho thấy mô hình hoạt động tốt với nhiều trường hợp rời bỏ. Tuy nhiên vẫn có khoảng 18.8% bị bỏ sót.
  - Specificity Mô hình dự đoán rất tốt các trường hợp không rời bỏ, với tỷ lệ 96.09%. Điều này cho thấy mô hình rất ít nhầm lẫn khi dự đoán lớp 0.

**Vẽ biểu đồ đường ROC để so sánh hiệu suất của hai mô hình**
```{r}
# Tính ROC-AUC
# Decision Tree
dt_roc <- roc(test_data$Exited, dt_prob)
dt_auc <- auc(dt_roc)
print(paste("Decision Tree ROC-AUC:", dt_auc))

# Random Forest
rf_roc <- roc(test_data$Exited, rf_prob)
rf_auc <- auc(rf_roc)
print(paste("Random Forest ROC-AUC:", rf_auc))

# Vẽ đường cong ROC
plot(dt_roc, col = "blue", main = "ROC giữa Decision Tree và Random Forest")
plot(rf_roc, col = "red", add = TRUE)
legend("bottomright", legend = c("Decision Tree", "Random Forest"), col = c("blue", "red"), lwd = 2)
```
- Đường cong ROC biểu diễn mối quan hệ giữa Sensitivity (độ nhạy, hay Recall) và 1 - Specificity (tỷ lệ False Positive Rate) tại các ngưỡng phân loại khác nhau. Đây là một công cụ phổ biến để đánh giá hiệu suất của mô hình phân loại nhị phân. Cả hai đường cong đều nằm phía trên đường chéo, cho thấy cả Decision Tree và Random Forest đều có hiệu suất tốt hơn đoán ngẫu nhiên.
- Đường cong của Random Forest (màu đỏ) nằm cao hơn và gần góc trên bên trái hơn so với đường cong của Decision Tree (màu xanh) ở hầu hết các điểm, điều này cho thấy Random Forest có Sensitivity cao hơn tại cùng một mức 1 - Specificity (FPR) so với Decision Tree.
- Thấy được rằng, Random Forest vượt trội hơn Decision Tree, Đường cong của Random Forest luôn nằm phía trên đường cong của Decision Tree, đặc biệt ở vùng FPR thấp (1 - Specificity từ 0 đến 0.5). Điều này cho thấy Random Forest có khả năng phát hiện khách hàng rời bỏ (Positive) tốt hơn mà không làm tăng tỷ lệ dự đoán sai (FP). Tại các ngưỡng phân loại khác nhau, Random Forest đạt được Sensitivity cao hơn với cùng mức FPR, hoặc đạt cùng mức Sensitivity với FPR thấp hơn. Random Forest có khả năng phát hiện khách hàng rời bỏ tốt hơn (Sensitivity cao hơn) tại cùng mức FPR, nghĩa là ít bỏ sót khách hàng rời bỏ hơn. Đồng thời, nó cũng giữ được Specificity cao, giảm thiểu việc dự đoán sai khách hàng không rời bỏ thành rời bỏ.

**So sánh các chỉ số kiểm thử**
- Để chọn ra mô hình phù hợp cho việc phân tích và dự đoán Churn của khách hàng ngân hàng, cần phải so sánh hiệu năng giữa các mô hình đó và chọn ra mô hình phù hợp với mục tiêu nhất. Tập trung so sánh những chỉ số quan trọng và được biểu diễn qua biểu đồ như sau:
```{r}
#So sánh các chỉ số
comparison <- data.frame(
  Model = c("Decision Tree", "Random Forest"),
  Accuracy = c(dt_confusion$overall["Accuracy"], rf_confusion$overall["Accuracy"]),
  Precision = c(dt_confusion$byClass["Precision"], rf_confusion$byClass["Precision"]),
  Recall = c(dt_confusion$byClass["Recall"], rf_confusion$byClass["Recall"]),
  F1_Score = c(dt_confusion$byClass["F1"], rf_confusion$byClass["F1"]),
  ROC_AUC = c(dt_auc, rf_auc)
)
print("So sánh Models:")
print(comparison)
```
**Trực quan hoá các số liệu để có cái nhìn rõ hơn**
```{r}
comparison_long <- melt(comparison, id.vars = "Model", 
                        variable.name = "Metric", 
                        value.name = "Value")

# Vẽ biểu đồ cột nhóm
ggplot(comparison_long, aes(x = Metric, y = Value, fill = Model)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = round(Value, 3)), 
            position = position_dodge(width = 1), 
            vjust = -0.5, size = 3.5) +
  labs(title = "So sánh hiệu năng giữa Decision Tree và Random Forest",
       x = "Chỉ số",
       y = "Giá trị",
       fill = "Model") +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
  scale_fill_manual(values = c("Decision Tree" = "#1f77b4", "Random Forest" = "#ff7f0e"))
```
- Biểu đồ đã biểu thị rất rõ độ lệch giữa hiệu năng của hai mô hình, mọi chỉ số của mô hình Random Forest đều tốt hơn Decision Tree và hiệu quả hơn rất nhiều. Ngoài ra, mục tiêu là dự đoán Churn khách hàng ngân hàng, đồng nghĩa với việc phân tích sự rời khỏi ngân hàng của khách hàng là rất quan trọng (dự đoán Exited là 1). Vì vậy ta cần tập trung nhiều nhất vào chỉ số Recall (Sensitive) khi tính tỷ lệ dự đoán đúng của mô hình trên thực tế, độ nhạy của mô hình Random Forest đạt lên đến 81.2% cho thấy sự nhạy cảm đối với dữ liệu thực tế, hạn chế bỏ sót những trường hợp rời đi của khách hàng. Ngoài ra, chỉ số Accuracy cũng cho thấy sự chính xác của mô hình, Precision 94.1% (tốt hơn 90.6% của Decision Tree) cũng cho thấy sự uy tín, chuẩn xác trong sự dự đoán của mô hình.

```{r}
# Xem tầm quan trọng của các đặc trưng
randomForest::importance(rf_model)
varImpPlot(rf_model, main = "Đặc trưng quan trọng của Random Forest")
```
Nhận xét:
Đối với MeanDecreaseAccuracy (Bên trái), thước đo này đánh giá mức độ giảm độ chính xác của mô hình nếu một đặc trưng bị loại bỏ hoặc được hoán đổi ngẫu nhiên. Giá trị càng cao, đặc trưng đó càng quan trọng vì việc loại bỏ nó làm giảm độ chính xác của mô hình nhiều hơn. Dựa theo biểu đồ thấy rõ được rằng:
  - Age (~100): Là đặc trưng quan trọng nhất, cho thấy tuổi tác có ảnh hưởng lớn đến dự đoán (có thể là biến Exited – khách hàng rời bỏ).
  - NumOfProducts (~80): Số lượng sản phẩm khách hàng sử dụng cũng rất quan trọng, đứng thứ hai.
  - IsActiveMember (~60): Trạng thái thành viên tích cực có ảnh hưởng đáng kể.
  - Balance (~50): Số dư tài khoản cũng là một yếu tố quan trọng.
  - Các đặc trưng khác như Gender, Geography, Satisfaction_Score, Card_Type, EstimatedSalary, Tenure, HasCrCard, Point_Earned, và CreditScore có mức độ quan trọng giảm dần, với giá trị từ ~40 trở xuống.
  - Đặc biệt, CreditScore (~10) có mức độ quan trọng thấp nhất, cho thấy điểm tín dụng ít ảnh hưởng đến dự đoán.

Đối với MeanDecreaseGini (Bên phải), thước đo này đánh giá mức độ giảm độ bất thuần (impurity) trung bình (dựa trên chỉ số Gini) khi sử dụng đặc trưng đó để phân tách trong các cây của Random Forest. Giá trị càng cao, đặc trưng đó càng hữu ích trong việc phân tách dữ liệu thành các lớp (ví dụ: Exited = 0 hoặc 1). Dựa theo biểu đồ thấy rõ được rằng:
  - Age (~800): Vẫn là đặc trưng quan trọng nhất, với giá trị rất cao, cho thấy tuổi tác có vai trò lớn trong việc giảm độ bất thuần khi phân tách dữ liệu.
  - NumOfProducts (~700): Đứng thứ hai, cũng rất quan trọng.
  - IsActiveMember (~400): Thành viên tích cực có ảnh hưởng lớn trong việc phân tách.
  - Gender_Male và Gender_Female (~300): Giới tính có ảnh hưởng đáng kể, nhưng thấp hơn các đặc trưng trên.
  - Balance, Geography_Germany, EstimatedSalary, và Point_Earned có giá trị từ ~200–300.
  - Các đặc trưng còn lại như Geography_France, Geography_Spain, Satisfaction_Score, Card_Type, Tenure, và CreditScore có giá trị thấp hơn, từ ~100 trở xuống.
  - Card_Type_SILVER (~50) và CreditScore (~50) có mức độ quan trọng thấp nhất theo thước đo này.
Qua những phân tích các đặc trưng trên sẽ giúp đem lại nhiều giá trị hữu ích và quan trọng trong việc thiết kế và xây dựng chiến lược, đem lại sự hiệu quả khi xây dựng mô hình dự doán Churn.

**Lưu mô hình để sử dụng**
```{r}
# Lưu mô hình
saveRDS(rf_model, "rf_model_churn.rds")
```

**Lưu dữ liệu đã được xử lý phục vụ quá trình huấn luyện mô hình**
```{r}
write.csv(encoded_data,"data_training.csv",row.names = FALSE)
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

